import tempfile

import tvm
from tvm import meta_schedule as ms
from tvm import tir
from tvm.script import tir as T
from tvm.tir.schedule import BlockRV
from tvm.meta_schedule.space_generator import ScheduleFn
from typing import Tuple

from evaluate import test_numerical_correctness
from gemm_relu_add import gemm_relu_add, M, N, K

def shared_memory_tiling(
    sch: tir.Schedule, tile_x: int, tile_y: int, tile_k: int
) -> Tuple[BlockRV, BlockRV]:
    """The implementation of shared memory tiling.

    Parameters
    ----------
    sch : tir.Schedule
        The schedule instance.

    tile_x : int
        The shared memory tile size along the `M` dimension.

    tile_y : int
        The shared memory tile size along the `N` dimension.

    tile_k : int
        The shared memory tile size along the `K` dimension.

    Returns
    -------
    A_shared : tir.schedule.BlockRV
        The generated shared memory read stage of `A`.
        It is returned for the cooperative fetching in later tasks.

    B_shared : tir.schedule.BlockRV
        The generated shared memory read stage of `B`.
        It is returned for the cooperative fetching in later tasks.

    Note
    ----
    - You can use `sch.show()` to print out the function after
    scheduling so far at any time.
    - We do not return `sch`, because it is in-place updated during scheduling.
    """

    return A_shared, B_shared


def register_tiling(
    sch: tir.Schedule,
    thread_tile_x: int,
    thread_tile_y: int,
    thread_tile_k: int,
) -> None:
    """The implementation of register tiling.

    Parameters
    ----------
    sch : tir.Schedule
        The schedule instance.

    thread_tile_x : int
        The register tile size along the `M` dimension.

    thread_tile_y : int
        The register tile size along the `N` dimension.

    thread_tile_k : int
        The register tile size along the `K` dimension.

    Note
    ----
    - You can use `sch.show()` to print out the function after
    scheduling so far at any time.
    - We do not return `sch`, because it is in-place updated during scheduling.
    """
def cooperative_fetching(
    sch: tir.Schedule,
    A_shared: BlockRV,
    B_shared: BlockRV,
    thread_extent_x: int,
    thread_extent_y: int,
) -> None:
    """The implementation of cooperative fetching.

    Parameters
    ----------
    sch : tir.Schedule
        The schedule instance.

    A_shared : tir.schedule.BlockRV
        The shared memory read stage of `A` generated by shared memory tiling.

    B_shared : tir.schedule.BlockRV
        The shared memory read stage of `B` generated by shared memory tiling.

    thread_extent_x : int
        The number of threads along the `x` dimension in a thread block,
        or equivalently, the value of `blockDim.x` in GPU.

    thread_extent_y : int
        The number of threads along the `y` dimension in a thread block,
        or equivalently, the value of `blockDim.y` in GPU.

    Note
    ----
    - You can use `sch.show()` to print out the function after
    scheduling so far at any time.
    - We do not return `sch`, because it is in-place updated during scheduling.
    """


def write_cache(sch: tir.Schedule) -> None:
    """The implementation of write cache.

    Parameters
    ----------
    sch : tir.Schedule
        The schedule instance.

    Note
    ----
    - You can use `sch.show()` to print out the function after
    scheduling so far at any time.
    - We do not return `sch`, because it is in-place updated during scheduling.
    """

def epilogue_fusion(sch: tir.Schedule) -> None:
    """The implementation of epilogue_fusion.

    Parameters
    ----------
    sch : tir.Schedule
        The schedule instance.

    Note
    ----
    - You can use `sch.show()` to print out the function after
    scheduling so far at any time.
    - We do not return `sch`, because it is in-place updated during scheduling.
    """
    # TODO: Use `get_block` to retrieve the addition computation and ReLU computation.

 
def auto_tuning_schedule(sch: tir.Schedule) -> tir.Schedule:
    """The function that defines the schedule space for automatic tuning.

    Parameters
    ----------
    sch : tir.Schedule
        An empty schedule of the GeMM + ReLU + add workload.

    Returns
    -------
    sch : tir.Schedule
        The updated schedule of the GeMM + ReLU + add workload.
    """

    """TODO: Your code here"""
    # NOTE: You may need to set argument `preserve_unit_loops=True`
    # in `compute_at` and `reverse_compute_at` to make it work
    # with auto tuning.

   # Create a schedule from the workload.
    # Define the shared memory tile sizes and register tile sizes.
    # tile_x, tile_y, tile_k = 64, 64, 64
    # thread_tile_x, thread_tile_y, thread_tile_k = 4, 4, 1

    # Step 1. Shared memory tiling.
    block_gemm = sch.get_block("gemm")
    # Fetch the loops outside the "gemm" block.
    i, j, k = sch.get_loops(block_gemm)

    # Split loop `i` into an outer loop and an inner loop with regard to tile_x.
    # Here `None` in `factors` means the factor of this loop will be
    # automatically inferred.
    i_outer_var, i_inner_var = sch.sample_perfect_tile(i, n = 2)
    i_outer, i_inner = sch.split(i, [i_outer_var, i_inner_var])
    # TODO: Split loop `j` into an outer loop and an inner loop with regard to tile_y.
    j_outer_var, j_inner_var = sch.sample_perfect_tile(j, n = 2)
    j_outer, j_inner = sch.split(j, [j_outer_var, j_inner_var])
    # TODO: Split loop `k` into an outer loop and an inner loop with regard to tile_k.
    k_outer_var, k_inner_var = sch.sample_perfect_tile(k, n = 2)
    k_outer, k_inner = sch.split(k, [k_outer_var, k_inner_var])
    # TODO: Reorder loops into order [i_outer, j_outer, k_outer, i_inner, j_inner, k_inner]
    sch.reorder(i_outer, j_outer, k_outer, i_inner, j_inner, k_inner)
    # TODO: Bind `i_outer` to blockIdx.x.
    sch.bind(i_outer, "blockIdx.x")
    # TODO: Bind `j_outer` to blockIdx.y.
    sch.bind(j_outer, "blockIdx.y")
    A_shared = sch.cache_read(block_gemm, read_buffer_index=0, storage_scope="shared")
    sch.compute_at(A_shared, k_outer, preserve_unit_loops=True)
    B_shared = sch.cache_read(block_gemm, read_buffer_index=1, storage_scope="shared")
    sch.compute_at(B_shared, k_outer, preserve_unit_loops=True)

    # Step 2. Register tiling.
    block_gemm = sch.get_block("gemm")
    i, j, k = sch.get_loops(block_gemm)[-3:]
    i_thread_outer_var, i_thread_inner_var = sch.sample_perfect_tile(i, n = 2)
    i_thread_outer, i_thread_inner = sch.split(i, [i_thread_outer_var, i_thread_inner_var])

    j_thread_outer_var, j_thread_inner_var = sch.sample_perfect_tile(j, n = 2)
    j_thread_outer, j_thread_inner = sch.split(j, [j_thread_outer_var, j_thread_inner_var])

    k_thread_outer_var, k_thread_inner_var = sch.sample_perfect_tile(k, n = 2)
    k_thread_outer, k_thread_inner = sch.split(k, [k_thread_outer_var, k_thread_inner_var])
    
    sch.reorder(i_thread_outer, j_thread_outer, k_thread_outer, i_thread_inner, j_thread_inner, k_thread_inner)
    sch.bind(i_thread_outer, "threadIdx.x")
    sch.bind(j_thread_outer, "threadIdx.y")
    A_thread = sch.cache_read(block_gemm, read_buffer_index=0, storage_scope="local")
    sch.compute_at(A_thread, k_thread_outer, preserve_unit_loops=True)
    B_thread = sch.cache_read(block_gemm, read_buffer_index=1, storage_scope="local")
    sch.compute_at(B_thread, k_thread_outer, preserve_unit_loops=True)
    # Step 3. Cooperative fetching.
    def _cooperative_fetching_impl(block: BlockRV):
        # TODO: Fetch the loops of the read stage with `get_loops`.
        i, j = sch.get_loops(block)[-2:]
        # Think about what loops and how many we want to fetch here?
        # TODO: Fuse these loops into a single loop.
        fused_loop = sch.fuse(i,j)
        # TODO: Split the fused loop into **three** loops.
        #       The inner two loops should have extent `thread_extent_y`
        #       and `thread_extent_x` respectively.
        # _, ii_var, jj_var  = sch.sample_perfect_tile(fused_loop, n = 3)
        _, ii, jj = sch.split(fused_loop, [None, i_thread_outer_var, j_thread_outer_var])


        # TODO: Bind two loops among to `threadIdx.x` and `threadIdx.y` respectively.
        sch.bind(ii, "threadIdx.x")
        sch.bind(jj, "threadIdx.y")

    _cooperative_fetching_impl(A_shared)
    _cooperative_fetching_impl(B_shared)

    # Step 4. Write cache.
    block_gemm = sch.get_block("gemm")
    # TODO: Use `sch.get_loops` to find out the location of inserting write cache.
    loop_index = 4
    write_cache_loc = sch.get_loops(block_gemm)[loop_index]

    # TODO: Generate the local register write stage for GeMM, whose write buffer index is 0.
    C_thread_local = sch.cache_write(block_gemm, write_buffer_index=0, storage_scope="local")

    # TODO: Move the generated write cache to the proper location with `reverse_compute_at`.
    sch.reverse_compute_at(C_thread_local,  write_cache_loc, preserve_unit_loops=True)
    # Step 5. Epilogue fusion.
    relu_operator = sch.get_block("relu")
    addition_operator = sch.get_block("add")

    # TODO: Use `reverse_compute_inline` to fuse addition into ReLU, and fuse ReLU into GeMM.
    sch.reverse_compute_inline(addition_operator)
    sch.reverse_compute_inline(relu_operator)

    return sch

def auto_tune():
    with tempfile.TemporaryDirectory() as work_dir:
        target = tvm.target.Target(
            {
                "kind": "cuda",
                "max_shared_memory_per_block": 49152,
                "max_threads_per_block": 1024,
                "thread_warp_size": 32,
            }
        )
        # Tune the workload and record the evaluated schedules into the database.
        database = ms.tir_integration.tune_tir(
            mod=gemm_relu_add,
            target=target,
            work_dir=work_dir,
            max_trials_global=64,  # We try 64 schedules in the search space.
            num_trials_per_iter=32,
            space=ScheduleFn(sch_fn=auto_tuning_schedule),
        )
        # Retrieve the best performant schedule from the database.
        sch = ms.tir_integration.compile_tir(database, gemm_relu_add, target)
        assert sch is not None, "No valid schedule found!"
        # Print out the optimized function and the schedule.
        sch.mod.show()
        sch.trace.show()
        # Test the numerical correctness.
        test_numerical_correctness(sch)


if __name__ == "__main__":
    auto_tune()
